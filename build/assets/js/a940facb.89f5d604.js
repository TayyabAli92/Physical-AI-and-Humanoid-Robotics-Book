"use strict";(globalThis.webpackChunkbook_project=globalThis.webpackChunkbook_project||[]).push([[785],{5702:(n,e,o)=>{o.r(e),o.d(e,{assets:()=>r,contentTitle:()=>s,default:()=>g,frontMatter:()=>l,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"module-4-vla/chapter-2-llm-planning","title":"LLM Planning: Large Language Models for Robotic Task Planning","description":"Discover how Large Language Models (LLMs) can be leveraged for high-level task planning and symbolic reasoning, translating human intent into robot actions.","source":"@site/docs/module-4-vla/chapter-2-llm-planning.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/chapter-2-llm-planning","permalink":"/physical-ai-robotics-book/docs/module-4-vla/chapter-2-llm-planning","draft":false,"unlisted":false,"editUrl":"https://github.com/TayyabAli92/Physical-AI-and-Humanoid-Robotics-Book/edit/main/book-project/docs/module-4-vla/chapter-2-llm-planning.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialsSidebar","previous":{"title":"Whisper: Speech Recognition for Robot Interaction","permalink":"/physical-ai-robotics-book/docs/module-4-vla/chapter-1-whisper"},"next":{"title":"Capstone: Autonomous Humanoid Project","permalink":"/physical-ai-robotics-book/docs/module-4-vla/chapter-3-capstone-autonomous-humanoid"}}');var i=o(4848),t=o(8453);const l={},s="LLM Planning: Large Language Models for Robotic Task Planning",r={},c=[];function d(n){const e={h1:"h1",header:"header",li:"li",mermaid:"mermaid",p:"p",ul:"ul",...(0,t.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.header,{children:(0,i.jsx)(e.h1,{id:"llm-planning-large-language-models-for-robotic-task-planning",children:"LLM Planning: Large Language Models for Robotic Task Planning"})}),"\n",(0,i.jsx)(e.p,{children:"Discover how Large Language Models (LLMs) can be leveraged for high-level task planning and symbolic reasoning, translating human intent into robot actions."}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Understanding LLM integration with robotic systems"}),"\n",(0,i.jsx)(e.li,{children:"Designing prompt engineering for robotic tasks"}),"\n",(0,i.jsx)(e.li,{children:"Implementing task decomposition and planning"}),"\n",(0,i.jsx)(e.li,{children:"Handling ambiguous or complex commands"}),"\n",(0,i.jsx)(e.li,{children:"Validating plans for safety and feasibility"}),"\n"]}),"\n",(0,i.jsx)(e.mermaid,{value:"graph TD\n    A[Human Command] --\x3e B[LLM Processing]\n    B --\x3e C[Task Decomposition]\n    C --\x3e D[Action Sequencing]\n    D --\x3e E[Robot Execution]\n    B --\x3e F[Context Understanding]\n    F --\x3e C"})]})}function g(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(d,{...n})}):d(n)}},8453:(n,e,o)=>{o.d(e,{R:()=>l,x:()=>s});var a=o(6540);const i={},t=a.createContext(i);function l(n){const e=a.useContext(t);return a.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(i):n.components||i:l(n.components),a.createElement(t.Provider,{value:e},n.children)}}}]);