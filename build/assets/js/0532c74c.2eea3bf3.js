"use strict";(globalThis.webpackChunkbook_project=globalThis.webpackChunkbook_project||[]).push([[4196],{9070:i=>{i.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialsSidebar":[{"type":"link","href":"/physical-ai-robotics-book/docs/intro","label":"Physical AI & Humanoid Robotics Book","docId":"intro","unlisted":false},{"type":"category","label":"Module 1 \u2013 ROS 2: The Robotic Nervous System","items":[{"type":"link","href":"/physical-ai-robotics-book/docs/module-1-ros2/intro","label":"Module 1 \u2013 ROS 2: The Robotic Nervous System","docId":"module-1-ros2/intro","unlisted":false},{"type":"link","href":"/physical-ai-robotics-book/docs/module-1-ros2/chapter-1-ros-basics","label":"ROS 2 Basics: Core Concepts","docId":"module-1-ros2/chapter-1-ros-basics","unlisted":false},{"type":"link","href":"/physical-ai-robotics-book/docs/module-1-ros2/chapter-2-nodes-topics","label":"ROS 2 Nodes and Topics","docId":"module-1-ros2/chapter-2-nodes-topics","unlisted":false},{"type":"link","href":"/physical-ai-robotics-book/docs/module-1-ros2/chapter-3-rclpy-agents","label":"RCLPY Agents: Programming with ROS 2 in Python","docId":"module-1-ros2/chapter-3-rclpy-agents","unlisted":false},{"type":"link","href":"/physical-ai-robotics-book/docs/module-1-ros2/chapter-4-urdf-for-humanoids","label":"URDF for Humanoids: Robot Description Format","docId":"module-1-ros2/chapter-4-urdf-for-humanoids","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2 \u2013 Digital Twin (Gazebo & Unity)","items":[{"type":"link","href":"/physical-ai-robotics-book/docs/module-2-digital-twin/intro","label":"Module 2 \u2013 Digital Twin (Gazebo & Unity)","docId":"module-2-digital-twin/intro","unlisted":false},{"type":"link","href":"/physical-ai-robotics-book/docs/module-2-digital-twin/chapter-1-gazebo-physics","label":"Gazebo Physics: Realistic Robot Simulation","docId":"module-2-digital-twin/chapter-1-gazebo-physics","unlisted":false},{"type":"link","href":"/physical-ai-robotics-book/docs/module-2-digital-twin/chapter-2-unity-visualization","label":"Unity Visualization: High-Fidelity Digital Twins","docId":"module-2-digital-twin/chapter-2-unity-visualization","unlisted":false},{"type":"link","href":"/physical-ai-robotics-book/docs/module-2-digital-twin/chapter-3-sensor-simulation","label":"Sensor Simulation: Perceiving the Virtual World","docId":"module-2-digital-twin/chapter-3-sensor-simulation","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3 \u2013 NVIDIA Isaac Platform","items":[{"type":"link","href":"/physical-ai-robotics-book/docs/module-3-isaac/intro","label":"Module 3 \u2013 NVIDIA Isaac Platform","docId":"module-3-isaac/intro","unlisted":false},{"type":"link","href":"/physical-ai-robotics-book/docs/module-3-isaac/chapter-1-isaac-sim","label":"Isaac Sim: Advanced Robotics Simulation","docId":"module-3-isaac/chapter-1-isaac-sim","unlisted":false},{"type":"link","href":"/physical-ai-robotics-book/docs/module-3-isaac/chapter-2-vslam","label":"VSLAM: Visual Simultaneous Localization and Mapping","docId":"module-3-isaac/chapter-2-vslam","unlisted":false},{"type":"link","href":"/physical-ai-robotics-book/docs/module-3-isaac/chapter-3-navigation-nav2","label":"Navigation (Nav2): Path Planning and Autonomous Movement","docId":"module-3-isaac/chapter-3-navigation-nav2","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4 \u2013 Vision-Language-Action","items":[{"type":"link","href":"/physical-ai-robotics-book/docs/module-4-vla/intro","label":"Module 4 \u2013 Vision-Language-Action","docId":"module-4-vla/intro","unlisted":false},{"type":"link","href":"/physical-ai-robotics-book/docs/module-4-vla/chapter-1-whisper","label":"Whisper: Speech Recognition for Robot Interaction","docId":"module-4-vla/chapter-1-whisper","unlisted":false},{"type":"link","href":"/physical-ai-robotics-book/docs/module-4-vla/chapter-2-llm-planning","label":"LLM Planning: Large Language Models for Robotic Task Planning","docId":"module-4-vla/chapter-2-llm-planning","unlisted":false},{"type":"link","href":"/physical-ai-robotics-book/docs/module-4-vla/chapter-3-capstone-autonomous-humanoid","label":"Capstone: Autonomous Humanoid Project","docId":"module-4-vla/chapter-3-capstone-autonomous-humanoid","unlisted":false}],"collapsed":true,"collapsible":true}]},"docs":{"intro":{"id":"intro","title":"Physical AI & Humanoid Robotics Book","description":"Welcome to the comprehensive guide on building AI-powered humanoid robots from simulation to reality. This book is designed to take you through the essential technologies and concepts needed to develop intelligent robotic systems.","sidebar":"tutorialsSidebar"},"module-1-ros2/chapter-1-ros-basics":{"id":"module-1-ros2/chapter-1-ros-basics","title":"ROS 2 Basics: Core Concepts","description":"This chapter delves into the foundational concepts of ROS 2, essential for building robust robotic applications.","sidebar":"tutorialsSidebar"},"module-1-ros2/chapter-2-nodes-topics":{"id":"module-1-ros2/chapter-2-nodes-topics","title":"ROS 2 Nodes and Topics","description":"This chapter focuses on two fundamental ROS 2 communication mechanisms: nodes and topics.","sidebar":"tutorialsSidebar"},"module-1-ros2/chapter-3-rclpy-agents":{"id":"module-1-ros2/chapter-3-rclpy-agents","title":"RCLPY Agents: Programming with ROS 2 in Python","description":"This chapter guides you through programming ROS 2 applications using rclpy, the Python client library for ROS 2.","sidebar":"tutorialsSidebar"},"module-1-ros2/chapter-4-urdf-for-humanoids":{"id":"module-1-ros2/chapter-4-urdf-for-humanoids","title":"URDF for Humanoids: Robot Description Format","description":"This chapter introduces the Unified Robot Description Format (URDF), a crucial XML format for describing robot kinematics, dynamics, and visual properties.","sidebar":"tutorialsSidebar"},"module-1-ros2/intro":{"id":"module-1-ros2/intro","title":"Module 1 \u2013 ROS 2: The Robotic Nervous System","description":"This module provides a foundational understanding of the Robot Operating System 2 (ROS 2) and its role as the nervous system for robotic applications. We will explore its core concepts, architecture, and how it facilitates the development of complex robotic applications, particularly for humanoid robots.","sidebar":"tutorialsSidebar"},"module-2-digital-twin/chapter-1-gazebo-physics":{"id":"module-2-digital-twin/chapter-1-gazebo-physics","title":"Gazebo Physics: Realistic Robot Simulation","description":"This chapter focuses on using Gazebo, a powerful 3D robotics simulator, to create realistic physics-based environments for humanoid robots.","sidebar":"tutorialsSidebar"},"module-2-digital-twin/chapter-2-unity-visualization":{"id":"module-2-digital-twin/chapter-2-unity-visualization","title":"Unity Visualization: High-Fidelity Digital Twins","description":"This chapter explores how to leverage Unity, a powerful real-time 3D development platform, to create high-fidelity visualizations for our digital twins.","sidebar":"tutorialsSidebar"},"module-2-digital-twin/chapter-3-sensor-simulation":{"id":"module-2-digital-twin/chapter-3-sensor-simulation","title":"Sensor Simulation: Perceiving the Virtual World","description":"This chapter focuses on the crucial aspect of sensor simulation within digital twins, enabling humanoid robots to perceive and interact with their virtual environments.","sidebar":"tutorialsSidebar"},"module-2-digital-twin/intro":{"id":"module-2-digital-twin/intro","title":"Module 2 \u2013 Digital Twin (Gazebo & Unity)","description":"This module introduces the concept of digital twins and their critical role in robotics development.","sidebar":"tutorialsSidebar"},"module-3-isaac/chapter-1-isaac-sim":{"id":"module-3-isaac/chapter-1-isaac-sim","title":"Isaac Sim: Advanced Robotics Simulation","description":"Discover NVIDIA Isaac Sim, a scalable and physically accurate robotics simulation platform. Learn to create virtual environments, simulate robots, and generate synthetic data for AI training.","sidebar":"tutorialsSidebar"},"module-3-isaac/chapter-2-vslam":{"id":"module-3-isaac/chapter-2-vslam","title":"VSLAM: Visual Simultaneous Localization and Mapping","description":"Delve into Visual SLAM (Simultaneous Localization and Mapping) using Isaac ROS. Understand how robots build maps of their environment while simultaneously tracking their own position.","sidebar":"tutorialsSidebar"},"module-3-isaac/chapter-3-navigation-nav2":{"id":"module-3-isaac/chapter-3-navigation-nav2","title":"Navigation (Nav2): Path Planning and Autonomous Movement","description":"Master robot navigation with Nav2 on the Isaac platform. This chapter covers path planning, obstacle avoidance, and autonomous movement in complex environments.","sidebar":"tutorialsSidebar"},"module-3-isaac/intro":{"id":"module-3-isaac/intro","title":"Module 3 \u2013 NVIDIA Isaac Platform","description":"This module provides an introduction to the NVIDIA Isaac platform, a comprehensive suite of tools for robotics development, simulation, and AI.","sidebar":"tutorialsSidebar"},"module-4-vla/chapter-1-whisper":{"id":"module-4-vla/chapter-1-whisper","title":"Whisper: Speech Recognition for Robot Interaction","description":"Learn to integrate OpenAI Whisper for robust speech-to-text capabilities, enabling robots to understand spoken commands and environmental audio cues.","sidebar":"tutorialsSidebar"},"module-4-vla/chapter-2-llm-planning":{"id":"module-4-vla/chapter-2-llm-planning","title":"LLM Planning: Large Language Models for Robotic Task Planning","description":"Discover how Large Language Models (LLMs) can be leveraged for high-level task planning and symbolic reasoning, translating human intent into robot actions.","sidebar":"tutorialsSidebar"},"module-4-vla/chapter-3-capstone-autonomous-humanoid":{"id":"module-4-vla/chapter-3-capstone-autonomous-humanoid","title":"Capstone: Autonomous Humanoid Project","description":"This capstone chapter integrates all learned concepts to build an autonomous humanoid robot. It covers advanced VLA techniques for complex, real-world interactions.","sidebar":"tutorialsSidebar"},"module-4-vla/intro":{"id":"module-4-vla/intro","title":"Module 4 \u2013 Vision-Language-Action","description":"This module explores Vision-Language-Action (VLA) models, integrating visual perception and natural language understanding for complex robotic task planning and execution.","sidebar":"tutorialsSidebar"},"module1-physical-ai/introduction":{"id":"module1-physical-ai/introduction","title":"Introduction to Physical AI","description":""},"module2-ros2/ai-ros-integration":{"id":"module2-ros2/ai-ros-integration","title":"AI-ROS Integration","description":""},"module2-ros2/architecture":{"id":"module2-ros2/architecture","title":"ROS 2 Architecture","description":""},"module2-ros2/launch-files":{"id":"module2-ros2/launch-files","title":"ROS 2 Launch Files","description":""},"module2-ros2/mini-project":{"id":"module2-ros2/mini-project","title":"ROS 2 Mini-Project","description":""},"module2-ros2/rclpy-programming":{"id":"module2-ros2/rclpy-programming","title":"RCLPY Programming","description":""},"module2-ros2/ros2-packages":{"id":"module2-ros2/ros2-packages","title":"ROS 2 Packages","description":""},"module2-ros2/urdf-fundamentals":{"id":"module2-ros2/urdf-fundamentals","title":"URDF Fundamentals","description":""},"module3-digital-twin/gazebo-physics":{"id":"module3-digital-twin/gazebo-physics","title":"Gazebo Physics Fundamentals","description":""},"module3-digital-twin/mini-project":{"id":"module3-digital-twin/mini-project","title":"Digital Twin Mini-Project","description":""},"module3-digital-twin/ros2-gazebo-unity-pipeline":{"id":"module3-digital-twin/ros2-gazebo-unity-pipeline","title":"ROS 2, Gazebo, and Unity Pipeline","description":""},"module3-digital-twin/sensor-simulation":{"id":"module3-digital-twin/sensor-simulation","title":"Sensor Simulation","description":""},"module3-digital-twin/unity-visualization":{"id":"module3-digital-twin/unity-visualization","title":"Unity Visualization","description":""},"module3-digital-twin/urdf-sdf-world":{"id":"module3-digital-twin/urdf-sdf-world","title":"URDF/SDF World Building","description":""},"module4-isaac/isaac-ros-perception":{"id":"module4-isaac/isaac-ros-perception","title":"Isaac ROS Perception","description":""},"module4-isaac/isaac-sim-setup":{"id":"module4-isaac/isaac-sim-setup","title":"Isaac Sim Setup and Workflow","description":""},"module4-isaac/mini-project":{"id":"module4-isaac/mini-project","title":"Perception + Navigation Pipeline Mini-Project","description":""},"module4-isaac/reinforcement-learning":{"id":"module4-isaac/reinforcement-learning","title":"Reinforcement Learning with Isaac Sim","description":""},"module4-isaac/sim-to-real":{"id":"module4-isaac/sim-to-real","title":"Sim-to-Real Transfer","description":""},"module4-isaac/synthetic-data":{"id":"module4-isaac/synthetic-data","title":"Synthetic Dataset Creation","description":""},"module4-isaac/vslam-nav2":{"id":"module4-isaac/vslam-nav2","title":"VSLAM and Nav2 Integration","description":""},"module5-vla/gpt-ros-planning":{"id":"module5-vla/gpt-ros-planning","title":"GPT for ROS 2 Action Planning","description":""},"module5-vla/mini-project":{"id":"module5-vla/mini-project","title":"Voice-controlled Humanoid Mini-Project","description":""},"module5-vla/multi-modal-interaction":{"id":"module5-vla/multi-modal-interaction","title":"Multi-modal Interaction","description":""},"module5-vla/task-planners":{"id":"module5-vla/task-planners","title":"Task Planners","description":""},"module5-vla/vision-language-integration":{"id":"module5-vla/vision-language-integration","title":"Vision-Language Integration","description":""},"module5-vla/vla-architecture":{"id":"module5-vla/vla-architecture","title":"VLA Architecture Overview","description":""},"module5-vla/whisper-integration":{"id":"module5-vla/whisper-integration","title":"Whisper Integration","description":""},"module6-capstone/capstone-project":{"id":"module6-capstone/capstone-project","title":"Capstone Project: Voice-Controlled Humanoid Robot","description":""},"module7-conclusion/conclusion":{"id":"module7-conclusion/conclusion","title":"Conclusion and Future Work","description":""},"workflow":{"id":"workflow","title":"Spec-Kit Plus Workflow","description":"How Specs Drive Content Creation"},"writing-guide":{"id":"writing-guide","title":"Writing Guide: APA Citations","description":""}}}}')}}]);