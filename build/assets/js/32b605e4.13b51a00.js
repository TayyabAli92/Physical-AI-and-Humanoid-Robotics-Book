"use strict";(globalThis.webpackChunkbook_project=globalThis.webpackChunkbook_project||[]).push([[6442],{8431:(i,e,n)=>{n.r(e),n.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"module-2-digital-twin/chapter-3-sensor-simulation","title":"Sensor Simulation: Perceiving the Virtual World","description":"This chapter focuses on the crucial aspect of sensor simulation within digital twins, enabling humanoid robots to perceive and interact with their virtual environments.","source":"@site/docs/module-2-digital-twin/chapter-3-sensor-simulation.md","sourceDirName":"module-2-digital-twin","slug":"/module-2-digital-twin/chapter-3-sensor-simulation","permalink":"/physical-ai-robotics-book/docs/module-2-digital-twin/chapter-3-sensor-simulation","draft":false,"unlisted":false,"editUrl":"https://github.com/TayyabAli92/Physical-AI-and-Humanoid-Robotics-Book/edit/main/book-project/docs/module-2-digital-twin/chapter-3-sensor-simulation.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialsSidebar","previous":{"title":"Unity Visualization: High-Fidelity Digital Twins","permalink":"/physical-ai-robotics-book/docs/module-2-digital-twin/chapter-2-unity-visualization"},"next":{"title":"Module 3 \u2013 NVIDIA Isaac Platform","permalink":"/physical-ai-robotics-book/docs/module-3-isaac/intro"}}');var o=n(4848),a=n(8453);const r={},s="Sensor Simulation: Perceiving the Virtual World",l={},c=[];function u(i){const e={h1:"h1",header:"header",li:"li",mermaid:"mermaid",p:"p",ul:"ul",...(0,a.R)(),...i.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"sensor-simulation-perceiving-the-virtual-world",children:"Sensor Simulation: Perceiving the Virtual World"})}),"\n",(0,o.jsx)(e.p,{children:"This chapter focuses on the crucial aspect of sensor simulation within digital twins, enabling humanoid robots to perceive and interact with their virtual environments.\nWe will cover the theory and practical implementation of simulating various sensors, including cameras, LiDAR, and IMUs, within both Gazebo and Unity.\nAccurate sensor data is vital for developing robust perception and navigation algorithms for physical robots."}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Principles of sensor simulation"}),"\n",(0,o.jsx)(e.li,{children:"Simulating cameras and image processing"}),"\n",(0,o.jsx)(e.li,{children:"Simulating LiDAR and point cloud generation"}),"\n",(0,o.jsx)(e.li,{children:"Simulating IMU and other proprioceptive sensors"}),"\n"]}),"\n",(0,o.jsx)(e.mermaid,{value:"graph TD\n    A[Sensor Simulation] --\x3e B[Camera Simulation]\n    A --\x3e C[LiDAR Simulation]\n    A --\x3e D[IMU Simulation]\n    B --\x3e E[Image Data]\n    C --\x3e F[Point Cloud Data]\n    D --\x3e G[Orientation Data]\n    E --\x3e H[Perception Pipeline]\n    F --\x3e H\n    G --\x3e H"})]})}function d(i={}){const{wrapper:e}={...(0,a.R)(),...i.components};return e?(0,o.jsx)(e,{...i,children:(0,o.jsx)(u,{...i})}):u(i)}},8453:(i,e,n)=>{n.d(e,{R:()=>r,x:()=>s});var t=n(6540);const o={},a=t.createContext(o);function r(i){const e=t.useContext(a);return t.useMemo(function(){return"function"==typeof i?i(e):{...e,...i}},[e,i])}function s(i){let e;return e=i.disableParentContext?"function"==typeof i.components?i.components(o):i.components||o:r(i.components),t.createElement(a.Provider,{value:e},i.children)}}}]);